{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функции для обучения моделей, запускавшиеся в Yandex DataSphere. Передаваемые и возвращаемые переменные в соответсвии с заданием"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Практика 1. Обучение многослойной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "\n",
    "def load_train(path):\n",
    "    features_train = np.load(path + 'train_features.npy')\n",
    "    target_train = np.load(path + 'train_target.npy')\n",
    "    features_train = features_train.reshape(\n",
    "        features_train.shape[0], 28 * 28) / 255.\n",
    "    return features_train, target_train\n",
    "\n",
    "\n",
    "def create_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=512, activation='relu', input_shape=input_shape))\n",
    "    model.add(Dense(units=512, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(model, train_data, test_data, batch_size=32, epochs=20,\n",
    "                steps_per_epoch=None, validation_steps=None):\n",
    "\n",
    "    features_train, target_train = train_data\n",
    "    features_test, target_test = test_data\n",
    "    model.fit(features_train, target_train,\n",
    "              validation_data=(features_test, target_test),\n",
    "              batch_size=batch_size, epochs=epochs,\n",
    "              steps_per_epoch=steps_per_epoch,\n",
    "              validation_steps=validation_steps,\n",
    "              verbose=2, shuffle=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (60000,)\n",
      "0.0 1.0\n",
      "(10000, 784) (10000,)\n",
      "0.0 1.0\n",
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "x_train = x_train.reshape(x_train.shape[0], 28 * 28) / 255\n",
    "x_test = x_test.reshape(x_test.shape[0], 28 * 28) / 255\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_train.min(), x_train.max())\n",
    "print(x_test.shape, y_test.shape)\n",
    "print(x_test.min(), x_test.max())\n",
    "print(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               401920    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model((784,))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 - 4s - loss: 0.6860 - acc: 0.7730 - val_loss: 0.5148 - val_acc: 0.8235 - 4s/epoch - 2ms/step\n",
      "Epoch 2/20\n",
      "1875/1875 - 3s - loss: 0.4751 - acc: 0.8330 - val_loss: 0.4803 - val_acc: 0.8269 - 3s/epoch - 2ms/step\n",
      "Epoch 3/20\n",
      "1875/1875 - 3s - loss: 0.4305 - acc: 0.8502 - val_loss: 0.4423 - val_acc: 0.8405 - 3s/epoch - 2ms/step\n",
      "Epoch 4/20\n",
      "1875/1875 - 3s - loss: 0.4044 - acc: 0.8581 - val_loss: 0.4358 - val_acc: 0.8435 - 3s/epoch - 2ms/step\n",
      "Epoch 5/20\n",
      "1875/1875 - 3s - loss: 0.3841 - acc: 0.8646 - val_loss: 0.4343 - val_acc: 0.8489 - 3s/epoch - 2ms/step\n",
      "Epoch 6/20\n",
      "1875/1875 - 3s - loss: 0.3680 - acc: 0.8707 - val_loss: 0.4078 - val_acc: 0.8552 - 3s/epoch - 2ms/step\n",
      "Epoch 7/20\n",
      "1875/1875 - 3s - loss: 0.3549 - acc: 0.8750 - val_loss: 0.3979 - val_acc: 0.8573 - 3s/epoch - 2ms/step\n",
      "Epoch 8/20\n",
      "1875/1875 - 3s - loss: 0.3429 - acc: 0.8774 - val_loss: 0.3776 - val_acc: 0.8645 - 3s/epoch - 2ms/step\n",
      "Epoch 9/20\n",
      "1875/1875 - 3s - loss: 0.3324 - acc: 0.8825 - val_loss: 0.3716 - val_acc: 0.8681 - 3s/epoch - 2ms/step\n",
      "Epoch 10/20\n",
      "1875/1875 - 3s - loss: 0.3224 - acc: 0.8852 - val_loss: 0.3799 - val_acc: 0.8646 - 3s/epoch - 2ms/step\n",
      "Epoch 11/20\n",
      "1875/1875 - 3s - loss: 0.3144 - acc: 0.8887 - val_loss: 0.3609 - val_acc: 0.8725 - 3s/epoch - 2ms/step\n",
      "Epoch 12/20\n",
      "1875/1875 - 3s - loss: 0.3069 - acc: 0.8895 - val_loss: 0.3539 - val_acc: 0.8735 - 3s/epoch - 2ms/step\n",
      "Epoch 13/20\n",
      "1875/1875 - 3s - loss: 0.2981 - acc: 0.8929 - val_loss: 0.3766 - val_acc: 0.8665 - 3s/epoch - 2ms/step\n",
      "Epoch 14/20\n",
      "1875/1875 - 3s - loss: 0.2914 - acc: 0.8939 - val_loss: 0.3446 - val_acc: 0.8766 - 3s/epoch - 2ms/step\n",
      "Epoch 15/20\n",
      "1875/1875 - 3s - loss: 0.2857 - acc: 0.8976 - val_loss: 0.3451 - val_acc: 0.8789 - 3s/epoch - 2ms/step\n",
      "Epoch 16/20\n",
      "1875/1875 - 3s - loss: 0.2782 - acc: 0.8993 - val_loss: 0.3529 - val_acc: 0.8728 - 3s/epoch - 2ms/step\n",
      "Epoch 17/20\n",
      "1875/1875 - 3s - loss: 0.2730 - acc: 0.9013 - val_loss: 0.3408 - val_acc: 0.8765 - 3s/epoch - 2ms/step\n",
      "Epoch 18/20\n",
      "1875/1875 - 3s - loss: 0.2671 - acc: 0.9033 - val_loss: 0.3392 - val_acc: 0.8786 - 3s/epoch - 2ms/step\n",
      "Epoch 19/20\n",
      "1875/1875 - 3s - loss: 0.2615 - acc: 0.9055 - val_loss: 0.3472 - val_acc: 0.8791 - 3s/epoch - 2ms/step\n",
      "Epoch 20/20\n",
      "1875/1875 - 3s - loss: 0.2569 - acc: 0.9076 - val_loss: 0.3274 - val_acc: 0.8858 - 3s/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x19d267fe8c0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(model, (x_train, y_train), (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Практика 2. Алгоритм Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import (\n",
    "    Dense,\n",
    "    Conv2D,\n",
    "    MaxPool2D,\n",
    "    Flatten,\n",
    "    Dropout,\n",
    "    BatchNormalization,\n",
    ")\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_train(path):\n",
    "    features_train = np.load(path + 'train_features.npy')\n",
    "    target_train = np.load(path + 'train_target.npy')\n",
    "    features_train = features_train.reshape(-1, 28, 28, 1) / 255.\n",
    "    return features_train, target_train\n",
    "\n",
    "\n",
    "def create_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(20, (3, 3), strides=1, padding=\"same\", activation=\"relu\",\n",
    "                     input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D((2, 2), strides=2, padding=\"same\"))\n",
    "    model.add(Conv2D(10, (3, 3), strides=1, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D((2, 2), strides=2, padding=\"same\"))\n",
    "    model.add(Conv2D(25, (3, 3), strides=1, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D((2, 2), strides=2, padding=\"same\"))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=512, activation=\"relu\"))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer=Adam(learning_rate=0.005), loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(model, train_data, test_data, batch_size=32, epochs=10,\n",
    "                steps_per_epoch=None, validation_steps=None):\n",
    "\n",
    "    features_train, target_train = train_data\n",
    "    features_test, target_test = test_data\n",
    "    model.fit(features_train, target_train,\n",
    "              validation_data=(features_test, target_test),\n",
    "              batch_size=batch_size, epochs=epochs,\n",
    "              steps_per_epoch=steps_per_epoch,\n",
    "              validation_steps=validation_steps,\n",
    "              verbose=1, shuffle=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "x_train = x_train.reshape(-1, 28, 28, 1) / 255\n",
    "x_test = x_test.reshape(-1, 28, 28, 1) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 20)        200       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 20)       80        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 20)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 10)        1810      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 14, 14, 10)        0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 14, 14, 10)       40        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 10)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 7, 7, 25)          2275      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 7, 7, 25)         100       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 25)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 400)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               205312    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 214,947\n",
      "Trainable params: 214,837\n",
      "Non-trainable params: 110\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model((28, 28, 1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 10s 4ms/step - loss: 0.4604 - acc: 0.8355 - val_loss: 0.3365 - val_acc: 0.8795\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3292 - acc: 0.8784 - val_loss: 0.3182 - val_acc: 0.8834\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3028 - acc: 0.8879 - val_loss: 0.2923 - val_acc: 0.8917\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2860 - acc: 0.8943 - val_loss: 0.2931 - val_acc: 0.8930\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2731 - acc: 0.8996 - val_loss: 0.2881 - val_acc: 0.8980\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2651 - acc: 0.9027 - val_loss: 0.2754 - val_acc: 0.9035\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2589 - acc: 0.9058 - val_loss: 0.3058 - val_acc: 0.8868\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2496 - acc: 0.9083 - val_loss: 0.2817 - val_acc: 0.8930\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2446 - acc: 0.9111 - val_loss: 0.2708 - val_acc: 0.9121\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2412 - acc: 0.9131 - val_loss: 0.3143 - val_acc: 0.8823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x22fb9432e00>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(model, (x_train, y_train), (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Практика 3. Свёрточные сети для классификации фруктов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    Conv2D,\n",
    "    MaxPool2D,\n",
    "    Flatten,\n",
    "    Dropout,\n",
    "    BatchNormalization,\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "def load_train(path):\n",
    "    datagen = ImageDataGenerator(\n",
    "        # validation_split=0.25,\n",
    "        rescale=1/255.,\n",
    "        # vertical_flip=True,\n",
    "        # horizontal_flip=True,\n",
    "        # rotation_range=90,\n",
    "        # width_shift_range=0.1,\n",
    "        # height_shift_range=0.1,\n",
    "        # zoom_range=0.1,\n",
    "    )\n",
    "\n",
    "    return datagen.flow_from_directory(\n",
    "        path,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=16,\n",
    "        class_mode='sparse',\n",
    "        #subset='training',\n",
    "    )\n",
    "\n",
    "\n",
    "def create_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(75, (3, 3), strides=1, padding=\"same\", activation=\"relu\",\n",
    "                     input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D((2, 2), strides=2, padding=\"same\"))\n",
    "    model.add(Conv2D(50, (3, 3), strides=1, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D((2, 2), strides=2, padding=\"same\"))\n",
    "    model.add(Conv2D(25, (3, 3), strides=1, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D((2, 2), strides=2, padding=\"same\"))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=512, activation=\"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(12, activation='softmax'))\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(model, train_data, test_data, batch_size=None, epochs=20,\n",
    "                steps_per_epoch=None, validation_steps=None):\n",
    "    # raise ValueError(type(train_data), type(test_data))\n",
    "    model.fit(train_data,\n",
    "        validation_data=test_data,\n",
    "        epochs=epochs, batch_size=batch_size,\n",
    "        steps_per_epoch=steps_per_epoch, #train_data.samples/train_data.batch_size,\n",
    "        validation_steps=validation_steps, #test_data.samples/test_data.batch_size,\n",
    "        verbose=2, shuffle=True)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Практика 4. ResNet в Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.resnet import ResNet50\n",
    "from tensorflow import keras\n",
    "\n",
    "def load_train(path):\n",
    "    datagen = ImageDataGenerator(\n",
    "        rescale=1/255.,\n",
    "        vertical_flip=True,\n",
    "        horizontal_flip=True,\n",
    "        rotation_range=90,\n",
    "        width_shift_range=0.15,\n",
    "        height_shift_range=0.15,\n",
    "        zoom_range=0.1,\n",
    "    )\n",
    "\n",
    "    return datagen.flow_from_directory(\n",
    "        path,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=16,\n",
    "        class_mode='sparse',\n",
    "    )\n",
    "\n",
    "\n",
    "def create_model(input_shape):\n",
    "    backbone = ResNet50(\n",
    "        weights='/datasets/keras_models/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "        input_shape=input_shape, \n",
    "        include_top=False)\n",
    "    #backbone.trainable = False\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(backbone)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(12, activation='softmax'))\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), \n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(model, train_data, test_data, batch_size=None, epochs=5,\n",
    "                steps_per_epoch=None, validation_steps=None):\n",
    "    #raise ValueError(type(train_data), type(test_data))\n",
    "    model.fit(train_data,\n",
    "        validation_data=test_data,\n",
    "        epochs=epochs, batch_size=batch_size,\n",
    "        steps_per_epoch=steps_per_epoch, #train_data.samples/train_data.batch_size,\n",
    "        validation_steps=validation_steps, #test_data.samples/test_data.batch_size,\n",
    "        verbose=2, shuffle=True)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проект"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.resnet import ResNet50\n",
    "from tensorflow import keras\n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "def load_train(path):\n",
    "    \"\"\" Loading of train dataset from 'final_files/' subfolder in `path`\n",
    "    \"\"\"\n",
    "    labels = pd.read_csv(path + 'labels.csv')\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        validation_split=0.25,\n",
    "        rescale=1/255.,\n",
    "        horizontal_flip=True,\n",
    "        width_shift_range=0.15,\n",
    "        height_shift_range=0.15,\n",
    "        zoom_range=0.1,\n",
    "    )\n",
    "\n",
    "    return datagen.flow_from_dataframe(\n",
    "        dataframe = labels,\n",
    "        directory = path+'final_files/',\n",
    "        x_col='file_name',\n",
    "        y_col='real_age',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='raw',\n",
    "        subset='training',\n",
    "        seed=123,\n",
    "    )\n",
    "\n",
    "\n",
    "def load_test(path):\n",
    "    \"\"\" Loading of test dataset from 'final_files/' subfolder in `path`\n",
    "    \"\"\"\n",
    "    labels = pd.read_csv(path + 'labels.csv')\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        validation_split=0.25,\n",
    "        rescale=1/255.)\n",
    "\n",
    "    return datagen.flow_from_dataframe(\n",
    "        dataframe=labels,\n",
    "        directory=path+'final_files/',\n",
    "        x_col='file_name',\n",
    "        y_col='real_age',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='raw',\n",
    "        subset='validation',\n",
    "        seed=123,\n",
    "    )\n",
    "\n",
    "\n",
    "def create_model(input_shape):\n",
    "    \"\"\" Creating of ResNet50 model for objects with shape = `input_shape`.  \n",
    "        Custom fully-connected layer at the top of the network with `relu` activation for predict age value\n",
    "    \"\"\"\n",
    "    backbone = ResNet50(\n",
    "        weights='/datasets/keras_models/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "        input_shape=input_shape, \n",
    "        include_top=False)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(backbone)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0005), \n",
    "                  loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(model, train_data, test_data, batch_size=None, epochs=20,\n",
    "                steps_per_epoch=None, validation_steps=None):\n",
    "    \"\"\" Training of `model`\n",
    "    \n",
    "    ----\n",
    "    `train_data` : DataFrameIterator for training dataset\n",
    "    `test_data` : DataFrameIterator for validation dataset\n",
    "    `epochs`, `batch_size` : params of keras.Model.fit()\n",
    "    \"\"\"\n",
    "    model.fit(train_data,\n",
    "        validation_data=test_data,\n",
    "        epochs=epochs, batch_size=batch_size,\n",
    "        steps_per_epoch=steps_per_epoch, #train_data.samples/train_data.batch_size,\n",
    "        validation_steps=validation_steps, #test_data.samples/test_data.batch_size,\n",
    "        verbose=2, shuffle=True)\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('tf-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3bcf6d0ff93c2043cfd4541d578fe9e4d8ddd22c852fc6afc85b234907176d88"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
